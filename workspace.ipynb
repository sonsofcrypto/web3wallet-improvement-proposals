{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "outputs": [],
   "source": [
    "template_integration_at_account = \"\"\"\n",
    "I would love to see ${AT_ACCOUNT} in #web3wallet ‚ù§Ô∏è‚Äçüî•üôè\n",
    "\n",
    "#WIP_${ID} ${TITLE}\n",
    "\n",
    "#byDegensForDegens #wips @sonsofcryptolab\n",
    "\"\"\"\n",
    "\n",
    "template_default = \"\"\"\n",
    "I would love this in #web3wallet ‚ù§Ô∏è‚Äçüî•üôè\n",
    "\n",
    "#WIP_${ID} ${TITLE}\n",
    "\n",
    "#byDegensForDegens #wips @sonsofcryptolab\n",
    "\"\"\"\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Category(Enum):\n",
    "    UNKNOWN = \"unknown\"\n",
    "    INFRASTRUCTURE = \"infrastructure\"\n",
    "    INTEGRATION = \"integration\"\n",
    "    FEATURE = \"feature\"\n",
    "\n",
    "    @staticmethod\n",
    "    def fromId(id: str):\n",
    "        if id[:1] == \"1\":\n",
    "            return Category.INFRASTRUCTURE\n",
    "        if id[:1] == \"2\":\n",
    "            return Category.INTEGRATION\n",
    "        if id[:1] == \"3\":\n",
    "            return Category.FEATURE\n",
    "        return Category.UNKNOWN\n",
    "\n",
    "\n",
    "def tweet(id, title, url, atAccount):\n",
    "    tweet_str = template_default\n",
    "    if Category.fromId(id) == Category.INTEGRATION and atAccount is not None:\n",
    "        tweet_str = template_integration_at_account\n",
    "        tweet_str = tweet_str.replace(\"${AT_ACCOUNT}\", atAccount)\n",
    "\n",
    "    tweet_str = tweet_str.replace(\"${ID}\", id)\n",
    "    tweet_str = tweet_str.replace(\"${TITLE}\", title)\n",
    "    tweet_str = tweet_str.replace(\"${URL}\", url)\n",
    "    return tweet_str.strip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [],
   "source": [
    "# Create proposals json file from ./proposals/*.md files\n",
    "\n",
    "proposals = []\n",
    "\n",
    "from pathlib import Path\n",
    "import re, json\n",
    "\n",
    "for p in Path('.').glob('proposals/*.md'):\n",
    "    filename = p.name.replace(\".md\", \"\")\n",
    "    id = filename.replace(\"wip-\", \"\")\n",
    "    category = id[:1] # First number in id\n",
    "    text = p.read_text()\n",
    "    # WIP-1001 ETH 2.0 support\n",
    "    title = re.search(\"\\n\\#\\s+WIP-\\d+\\s+(.+)\\n*\", text).group(1)\n",
    "    body = re.search(\"\\n\\#\\s+WIP-\\d+\\s+.+\\n*(.*)\", text).group(1)\n",
    "    atAccount = re.search(\".*\\[_metadata_:at_account\\]:-\\s\\\"*(.+)\\s*\\\"\", text)\n",
    "    atAccount = None if atAccount is None else atAccount.group(1)\n",
    "    page_url = (\"https://sonsofcrypto.com/web3wallet-improvement-proposals/v2/static/\"+id+\".html\")\n",
    "\n",
    "    proposals.append({\n",
    "        \"id\": id,\n",
    "        \"title\": title,\n",
    "        \"body\": body,\n",
    "        \"category\": Category.fromId(id).value,\n",
    "        \"at_account\": atAccount,\n",
    "        \"tweet\": tweet(id, title, page_url, atAccount),\n",
    "        \"image_url\": (\"https://sonsofcrypto.com/web3wallet-improvement-proposals/v2/images/\"+id+\".png\"),\n",
    "        \"page_url\": page_url,\n",
    "        \"creation_date\": \"2022-08-28T00:00:00.000Z\",\n",
    "        \"votes\": 0,\n",
    "    })\n",
    "file = open('proposals-list.json', 'w')\n",
    "file.write(json.dumps(proposals))\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "outputs": [],
   "source": [
    "# Create static page from template each proposal ./static/${PROPOSAL_ID}.html\n",
    "templateFile = open('./v2/static/template.html', 'r')\n",
    "template = templateFile.read()\n",
    "templateFile.close()\n",
    "\n",
    "for p in proposals:\n",
    "    t = template\n",
    "    t = t.replace(\"${ID}\", p[\"id\"])\n",
    "    t = t.replace(\"${TITLE}\", p[\"title\"])\n",
    "    t = t.replace(\"${DESCRIPTION}\", \"web3Wallet improvement proposal \" + p[\"id\"])\n",
    "    t = t.replace(\"${IMAGE_URL}\", p[\"image_url\"].replace(\"\\\\\", \"\"))\n",
    "    t = t.replace(\"${CONTENT}\", p[\"body\"].replace(\"\\\\u\", \"\\\\n\")) # Picks up \\u instead of \\n\n",
    "    t = t.replace(\"${URL}\", p[\"page_url\"].replace(\"\\\\\", \"\"))\n",
    "    file = open('./v2/static/'+p[\"id\"]+'.html', 'w')\n",
    "    file.write(t)\n",
    "    file.close()\n",
    "\n",
    "# Create proposals index page NOTE: in progress\n",
    "with open('./v2/index.md', 'w') as file:\n",
    "    for p in sorted(proposals, key=lambda p: p[\"id\"]):\n",
    "        t = \"- WIP-\" + p[\"id\"] + \" \" + p[\"title\"] + \"\\n\"\n",
    "        file.write(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 0.5 seconds each query\n",
      "Processing: hashtag: #WIP_2022, count: 0 (0 new), start_time: 2022-09-26T06:15:22Z\n",
      "Processing: hashtag: #WIP_2016, count: 6 (0 new), start_time: 2022-09-26T06:15:23Z\n",
      "Processing: hashtag: #WIP_2006, count: 0 (0 new), start_time: 2022-09-26T06:15:24Z\n",
      "Processing: hashtag: #WIP_2012, count: 5 (5 new), start_time: 2022-09-26T06:15:25Z\n",
      "Processing: hashtag: #WIP_2026, count: 3 (0 new), start_time: 2022-09-26T06:15:26Z\n",
      "Processing: hashtag: #WIP_2002, count: 0 (0 new), start_time: 2022-09-26T06:15:27Z\n",
      "Processing: hashtag: #WIP_2013, count: 5 (5 new), start_time: 2022-09-26T06:15:27Z\n",
      "Processing: hashtag: #WIP_2027, count: 7 (2 new), start_time: 2022-09-26T06:15:28Z\n",
      "Processing: hashtag: #WIP_2003, count: 0 (0 new), start_time: 2022-09-26T06:15:29Z\n",
      "Processing: hashtag: #WIP_2017, count: 3 (1 new), start_time: 2022-09-26T06:15:30Z\n",
      "Processing: hashtag: #WIP_2007, count: 10 (5 new), start_time: 2022-09-26T06:15:31Z\n",
      "Processing: hashtag: #WIP_2028, count: 1 (1 new), start_time: 2022-09-26T06:15:31Z\n",
      "Processing: hashtag: #WIP_1006, count: 8 (1 new), start_time: 2022-09-26T06:15:32Z\n",
      "Processing: hashtag: #WIP_3002, count: 14 (7 new), start_time: 2022-09-26T06:15:33Z\n",
      "Processing: hashtag: #WIP_2018, count: 7 (7 new), start_time: 2022-09-26T06:15:34Z\n",
      "Processing: hashtag: #WIP_1002, count: 8 (3 new), start_time: 2022-09-26T06:15:35Z\n",
      "Processing: hashtag: #WIP_3006, count: 7 (5 new), start_time: 2022-09-26T06:15:35Z\n",
      "Processing: hashtag: #WIP_2008, count: 0 (0 new), start_time: 2022-09-26T06:15:36Z\n",
      "Processing: hashtag: #WIP_2019, count: 9 (9 new), start_time: 2022-09-26T06:15:37Z\n",
      "Processing: hashtag: #WIP_1003, count: 10 (1 new), start_time: 2022-09-26T06:15:38Z\n",
      "Processing: hashtag: #WIP_2009, count: 5 (0 new), start_time: 2022-09-26T06:15:39Z\n",
      "Processing: hashtag: #WIP_3003, count: 1 (0 new), start_time: 2022-09-26T06:15:39Z\n",
      "Processing: hashtag: #WIP_3004, count: 1 (0 new), start_time: 2022-09-26T06:15:40Z\n",
      "Processing: hashtag: #WIP_1004, count: 17 (8 new), start_time: 2022-09-26T06:15:41Z\n",
      "Processing: hashtag: #WIP_1005, count: 4 (3 new), start_time: 2022-09-26T06:15:42Z\n",
      "Processing: hashtag: #WIP_3001, count: 2 (0 new), start_time: 2022-09-26T06:15:43Z\n",
      "Processing: hashtag: #WIP_1001, count: 17 (2 new), start_time: 2022-09-26T06:15:43Z\n",
      "Processing: hashtag: #WIP_3005, count: 5 (0 new), start_time: 2022-09-26T06:15:44Z\n",
      "Processing: hashtag: #WIP_2010, count: 0 (0 new), start_time: 2022-09-26T06:15:45Z\n",
      "Processing: hashtag: #WIP_2024, count: 0 (0 new), start_time: 2022-09-26T06:15:46Z\n",
      "Processing: hashtag: #WIP_2020, count: 1 (0 new), start_time: 2022-09-26T06:15:46Z\n",
      "Processing: hashtag: #WIP_2014, count: 5 (0 new), start_time: 2022-09-26T06:15:47Z\n",
      "Processing: hashtag: #WIP_2004, count: 0 (0 new), start_time: 2022-09-26T06:15:48Z\n",
      "Processing: hashtag: #WIP_2021, count: 5 (0 new), start_time: 2022-09-26T06:15:49Z\n",
      "Processing: hashtag: #WIP_2015, count: 4 (1 new), start_time: 2022-09-26T06:15:49Z\n",
      "Processing: hashtag: #WIP_2005, count: 0 (0 new), start_time: 2022-09-26T06:15:50Z\n",
      "Processing: hashtag: #WIP_2011, count: 0 (0 new), start_time: 2022-09-26T06:15:51Z\n",
      "Processing: hashtag: #WIP_2025, count: 0 (0 new), start_time: 2022-09-26T06:15:52Z\n",
      "Processing: hashtag: #WIP_2001, count: 25 (3 new), start_time: 2022-09-26T06:15:53Z\n",
      "Writing file: proposals-votes.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Have to run step one to have proposals in memory\n",
    "#\n",
    "# Might be better ways but this is one way to get a Twitter bearer token\n",
    "# 1. https://oauth-playground.glitch.me/?id=tweetsRecentSearch\n",
    "# 2. Run a query and authorize with Twitter account\n",
    "# 3. Click the dots on the right hand side\n",
    "# 4. Click Include access token\n",
    "# 5. It should now be visible in the query, just capture the <code>:\n",
    "# -H \"Authorization: Bearer <code>\"\n",
    "# It will expire after 6 hours or something\n",
    "\n",
    "# Download votes (number of tweets with hashtag for given proposal)\n",
    "import os, tweepy, time, json\n",
    "from datetime import datetime, timedelta, date\n",
    "from dateutil.parser import isoparse\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Get proposals\n",
    "proposalsFile = open('./proposals-list.json', 'r')\n",
    "proposals = json.loads(proposalsFile.read())\n",
    "proposalsFile.close()\n",
    "if type(proposals) is not list:\n",
    "    exit (\"No proposals found\")\n",
    "# Get votes\n",
    "try:\n",
    "    votesFile = open('./proposals-votes.json', 'r')\n",
    "    votes = json.loads(votesFile.read())\n",
    "    votesFile.close()\n",
    "except:\n",
    "    votes = False\n",
    "    print(\">>> No votes file found, creating a new file.\")\n",
    "\n",
    "proposalVotes = []\n",
    "\n",
    "\n",
    "api_key = os.environ.get(\"TWITTER_API\", \"\")\n",
    "api_key_secret = os.environ.get(\"TWITTER_API_SECRET\", \"\")\n",
    "bearer_token = os.environ.get(\"TWITTER_BEARER_TOKEN\", \"\")\n",
    "\n",
    "\n",
    "if api_key == \"\" or api_key_secret == \"\":\n",
    "    exit(\"API keys not set for twitter, please set in env TWITTER_API and TWITTER_API_SECRET\")\n",
    "\n",
    "# Connect to twitter API\n",
    "max_results = 100\n",
    "sleep_time = 0.5 # seconds\n",
    "\n",
    "#auth = tweepy.OAuth2BearerHandler(bearer_token);\n",
    "#api = tweepy.Client(auth)\n",
    "api = tweepy.Client(bearer_token=bearer_token)\n",
    "\n",
    "print (\"Sleeping \"+ str(sleep_time) + \" seconds each query\")\n",
    "\n",
    "def find_votes(_proposal):\n",
    "    if not votes:\n",
    "        return 0\n",
    "    for _vote in votes:\n",
    "        if _vote['id'] == _proposal['id']:\n",
    "            return _vote\n",
    "    return 0\n",
    "\n",
    "for proposal in proposals:\n",
    "    # Needs to happen in loop since time is moving while executing\n",
    "    today = datetime.utcnow()\n",
    "    week_ago = today - timedelta(days=7) + timedelta(minutes=1)\n",
    "\n",
    "    vote = find_votes(proposal)\n",
    "    start_time = week_ago\n",
    "    count = 0\n",
    "\n",
    "    if vote != 0 and vote and vote['start_time'] and week_ago < isoparse(vote['start_time']):\n",
    "        start_time = isoparse(vote['start_time'])\n",
    "        count = vote['count']\n",
    "        previous_count = vote['count']\n",
    "    start_time = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    hashtag = \"#WIP_\"+proposal.get(\"id\") #\"#WIP_3001\"\n",
    "\n",
    "    next_token = 0\n",
    "    while next_token != -1:\n",
    "        if (next_token == 0):\n",
    "            response = api.search_recent_tweets(query=hashtag, start_time=start_time, max_results=max_results)\n",
    "        else:\n",
    "            response = api.search_recent_tweets(query=hashtag, next_token=next_token, max_results=max_results)\n",
    "\n",
    "        response_count = int(response.meta['result_count'])\n",
    "        count = count+response_count\n",
    "        print (\"Processing: hashtag: \"+hashtag+\n",
    "               \", count: \"+ str(count) + \" (\" + str(count-previous_count) + \" new)\" +\n",
    "               \", start_time: \"+ today.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "               )\n",
    "\n",
    "        next_token = -1\n",
    "        if response_count == 100 and response.meta['next_token']:\n",
    "            next_token = response.meta['next_token']\n",
    "\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    proposalVotes.append({\n",
    "        \"count\": count,\n",
    "        \"hashtag\": hashtag,\n",
    "        \"start_time\": today.isoformat(),\n",
    "        \"id\": proposal[\"id\"]\n",
    "    })\n",
    "\n",
    "print(\"Writing file: proposals-votes.json\")\n",
    "file = open('proposals-votes.json', 'w')\n",
    "file.write(json.dumps(proposalVotes))\n",
    "file.close()\n",
    "print(\"Done.\")\n",
    "# Retrieve twitter posts with hastag\n",
    "\n",
    "# Count posts\n",
    "\n",
    "# Apply to correct place\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
